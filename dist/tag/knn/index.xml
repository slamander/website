<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>KNN | Baecher Research</title><link>https://alexbaecher.com/tag/knn/</link><atom:link href="https://alexbaecher.com/tag/knn/index.xml" rel="self" type="application/rss+xml"/><description>KNN</description><generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><copyright>© 2025 Alex Baecher</copyright><lastBuildDate>Fri, 22 Oct 2021 00:40:04 -0700</lastBuildDate><image><url>https://alexbaecher.com/media/logo_hu2039277577754200582.png</url><title>KNN</title><link>https://alexbaecher.com/tag/knn/</link></image><item><title>Machine Learning the 'Tidy' Way</title><link>https://alexbaecher.com/post/ml-tidymodels/</link><pubDate>Fri, 22 Oct 2021 00:40:04 -0700</pubDate><guid>https://alexbaecher.com/post/ml-tidymodels/</guid><description>&lt;h2 id="introduction-to-machine-learning-with-tidymodels">Introduction to machine learning with &lt;code>tidymodels&lt;/code>&lt;/h2>
&lt;h2 id="tidymodels-provides-a-clean-organized-and--most-importantly--consistent-programming-syntax-for-data-pre-processing-model-specification-model-fitting-model-evaluation-and-prediction">&lt;code>Tidymodels&lt;/code> provides a clean, organized, and&amp;ndash;most importantly&amp;ndash;consistent programming syntax for data pre-processing, model specification, model fitting, model evaluation, and prediction.&lt;/h2>
&lt;h1 id="anatomy-of-tidymodels">Anatomy of &lt;code>tidymodels&lt;/code>&lt;/h1>
&lt;h2 id="a-meta-package-that-installs-and-load-the-core-packages-listed-below-that-you-need-for-modeling-and-machine-learning">a meta-package that installs and load the core packages listed below that you need for modeling and machine learning&lt;/h2>
&lt;h2 id="rsamples-provides-infrastructure-for-efficient-data-splitting-and-resampling">&lt;code>rsamples&lt;/code>: provides infrastructure for efficient data splitting and resampling&lt;/h2>
&lt;h2 id="parsnip-a-tidy-unified-interface-to-models-that-can-be-used-to-try-a-range-of-models-without-getting-bogged-down-in-the-syntactical-minutiae-of-the-underlying-packages">&lt;code>parsnip&lt;/code>: a tidy, unified interface to models that can be used to try a range of models without getting bogged down in the syntactical minutiae of the underlying packages&lt;/h2>
&lt;h2 id="recipes-a-tidy-interface-to-data-pre-processing-tools-for-feature-engineering">&lt;code>recipes&lt;/code>: a tidy interface to data pre-processing tools for feature engineering&lt;/h2>
&lt;h2 id="workflows-workflows-bundle-your-pre-processing-modeling-and-post-processing-together">&lt;code>workflows&lt;/code>: workflows bundle your pre-processing, modeling, and post-processing together&lt;/h2>
&lt;h2 id="tune-helps-you-optimize-the-hyperparameters-of-your-model-and-pre-processing-steps">&lt;code>tune&lt;/code>: helps you optimize the hyperparameters of your model and pre-processing steps&lt;/h2>
&lt;h2 id="yardstick-measures-the-effectiveness-of-models-using-performance-metrics">&lt;code>yardstick&lt;/code>: measures the effectiveness of models using performance metrics&lt;/h2>
&lt;h2 id="dials-contains-tools-to-create-and-manage-values-of-tuning-parameters-and-is-designed-to-integrate-well-with-the-parsnip-package">&lt;code>dials&lt;/code>: contains tools to create and manage values of tuning parameters and is designed to integrate well with the parsnip package&lt;/h2>
&lt;h2 id="broom-summarizes-key-information-about-models-in-tidy-tibbles">&lt;code>broom&lt;/code>: summarizes key information about models in tidy tibble()s&lt;/h2>
&lt;p>First, lets load the &lt;code>tidymodels&lt;/code> meta-package:&lt;/p>
&lt;pre>&lt;code>library(tidymodels)
library(tidyverse)
&lt;/code>&lt;/pre>
&lt;h1 id="package-tutorials">Package tutorials:&lt;/h1>
&lt;h2 id="data">Data&lt;/h2>
&lt;p>I&amp;rsquo;ll demonstrate it&amp;rsquo;s features using an existing data set from Bruno Oliveria, &lt;code>Amphibio&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>Link to publication: &lt;a href="https://www.nature.com/articles/sdata2017123" target="_blank" rel="noopener">https://www.nature.com/articles/sdata2017123&lt;/a>&lt;/li>
&lt;li>Link to data: &lt;a href="https://ndownloader.figstatic.com/files/8828578" target="_blank" rel="noopener">https://ndownloader.figstatic.com/files/8828578&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="amphibio-data">Amphibio data&lt;/h3>
&lt;p>Download data:&lt;/p>
&lt;pre>&lt;code># install.packages(&amp;quot;downloader&amp;quot;)
# library(downloader)
#
# url &amp;lt;- &amp;quot;https://ndownloader.figstatic.com/files/8828578&amp;quot;
# download(url, dest=&amp;quot;dial_broom/amphibio.zip&amp;quot;, mode=&amp;quot;wb&amp;quot;)
# unzip(&amp;quot;dial_broom/amphibio.zip&amp;quot;, exdir = &amp;quot;./dial_broom&amp;quot;)
library(readr)
amphibio_raw &amp;lt;- read_csv(&amp;quot;AmphiBIO_v1.csv&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>The data consist of natural history information of amphibians, including
habitat types, diet, size, ect.&lt;/p>
&lt;p>Here&amp;rsquo;s the breakdown of taxonomic spread in the data:&lt;/p>
&lt;ul>
&lt;li>Order: N = 3&lt;/li>
&lt;li>Family: N = 61&lt;/li>
&lt;li>Genera: N = 531&lt;/li>
&lt;li>Species: N = 6776&lt;/li>
&lt;/ul>
&lt;p>There are also a lot of missing data, and what data do exist are wildly
different scales. We&amp;rsquo;ll clean this up:&lt;/p>
&lt;pre>&lt;code># Check how many NA's for each row
amphibio &amp;lt;- amphibio_raw %&amp;gt;%
select(&amp;quot;Order&amp;quot;
,&amp;quot;Body_mass_g&amp;quot;
,&amp;quot;Body_size_mm&amp;quot;
,&amp;quot;Litter_size_min_n&amp;quot;
,&amp;quot;Litter_size_max_n&amp;quot;
,&amp;quot;Reproductive_output_y&amp;quot;
) %&amp;gt;%
na.omit %&amp;gt;%
mutate(Body_mass_g = log(Body_mass_g),
Body_size_mm = log(Body_size_mm),
Litter_size_min_n = log(Litter_size_min_n),
Litter_size_max_n = log(Litter_size_max_n),
Reproductive_output_y = log(Reproductive_output_y)) %&amp;gt;%
filter(!Order == &amp;quot;Gymnophiona&amp;quot;)
amphibio %&amp;gt;%
group_by(Order) %&amp;gt;%
summarize(n = n())
&lt;/code>&lt;/pre>
&lt;p>Now let&amp;rsquo;s have a peak at the data:&lt;/p>
&lt;pre>&lt;code> amphibio %&amp;gt;%
pivot_longer(!Order, names_to = &amp;quot;Metric&amp;quot;, values_to = &amp;quot;Value&amp;quot;) %&amp;gt;%
ggplot(aes(Order, Value, col = Order)) +
geom_boxplot() +
facet_wrap(~Metric)
&lt;/code>&lt;/pre>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt=" " srcset="
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-4-1_hu414051968656277047.webp 400w,
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-4-1_hu16502879561273140279.webp 760w,
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-4-1_hu16367533267459427282.webp 1200w"
src="https://alexbaecher.com/media/posts/script_files/figure-markdown_strict/unnamed-chunk-4-1_hu414051968656277047.webp"
width="672"
height="480"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
&lt;/figcaption>&lt;/figure>
&lt;p>There are some trends in the data:&lt;/p>
&lt;ul>
&lt;li>caudates are longer&lt;/li>
&lt;li>anura have larger litter sizes&lt;/li>
&lt;/ul>
&lt;p>Given the data, one possible modeling application could be to use data
to predict order using two models: knn and boosted regression trees.&lt;/p>
&lt;p>To start the modeling process, we&amp;rsquo;ll use &lt;code>rsamples&lt;/code> to split the data
into training and testing sets.&lt;/p>
&lt;pre>&lt;code>set.seed(42)
tidy_split &amp;lt;- initial_split(amphibio, prop = 0.95)
tidy_train &amp;lt;- training(tidy_split)
tidy_test &amp;lt;- testing(tidy_split)
tidy_kfolds &amp;lt;- vfold_cv(tidy_train)
&lt;/code>&lt;/pre>
&lt;p>We can use &lt;code>recipes&lt;/code> to preprocess the data:&lt;/p>
&lt;pre>&lt;code># Recipes package
## For preprocessing, feature engineering, and feature elimination
tidy_rec &amp;lt;- recipe(Order ~ ., data = tidy_train) %&amp;gt;%
step_dummy(all_nominal(), -all_outcomes()) %&amp;gt;%
step_normalize(all_predictors()) %&amp;gt;%
prep()
&lt;/code>&lt;/pre>
&lt;p>Now that we&amp;rsquo;ve created a recipe to process the data for modeling, we can
use &lt;code>parsnip&lt;/code> to model the data:&lt;/p>
&lt;p>First, let&amp;rsquo;s have a look at the model’s description&lt;/p>
&lt;pre>&lt;code>library(&amp;quot;webshot&amp;quot;)
# ?boost_tree
&lt;/code>&lt;/pre>
&lt;iframe src="https://parsnip.tidymodels.org/reference/boost_tree.html" width="100%" height="400px">
&lt;/iframe>
&lt;h2 id="boost_tree">&lt;code>boost_tree()&lt;/code>&lt;/h2>
&lt;h3 id="description">Description&lt;/h3>
&lt;p>&lt;code>boost_tree()&lt;/code> defines a model that creates a series of decision trees
forming an ensemble. Each tree depends on the results of previous trees.
All trees in the ensemble are combined to produce a final prediction.&lt;/p>
&lt;p>There are different ways to fit this model. See the engine-specific
pages for more details:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>xgboost (default)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>C5.0&lt;/p>
&lt;/li>
&lt;li>
&lt;p>spark&lt;/p>
&lt;h1 id="nearest_neighbors">?nearest_neighbors&lt;/h1>
&lt;/li>
&lt;/ul>
&lt;iframe src="https://parsnip.tidymodels.org/reference/nearest_neighbor.html" width="100%" height="400px">
&lt;/iframe>
&lt;h2 id="nearest_neighbor">&lt;code>nearest_neighbor()&lt;/code>:&lt;/h2>
&lt;h3 id="defines-a-model-that-uses-the-k-most-similar-data-points-from-the-training-set-to-predict-new-samples">defines a model that uses the K most similar data points from the training set to predict new samples.&lt;/h3>
&lt;h3 id="there-are-different-ways-to-fit-this-model-see-the-engine-specific-pages-for-more-details">There are different ways to fit this model. See the engine-specific pages for more details:&lt;/h3>
&lt;ul>
&lt;li>knn (default)&lt;/li>
&lt;/ul>
&lt;p>Now, let&amp;rsquo;s fit the models:&lt;/p>
&lt;pre>&lt;code># Parsnip package
## Standardized api for creating models
tidy_boosted_model &amp;lt;- boost_tree(trees = tune(),
min_n = tune(),
learn_rate = tune()) %&amp;gt;%
set_mode(&amp;quot;classification&amp;quot;) %&amp;gt;%
set_engine(&amp;quot;xgboost&amp;quot;)
tidy_knn_model &amp;lt;- nearest_neighbor(neighbors = tune()) %&amp;gt;%
set_mode(&amp;quot;classification&amp;quot;) %&amp;gt;%
set_engine(&amp;quot;kknn&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>Our basic model recipe is complete, but now we want to use &lt;code>dials&lt;/code> to
tune parameters.&lt;/p>
&lt;h1 id="dials">&lt;code>dials&lt;/code>&lt;/h1>
&lt;p>For boosted regression trees, there are 3 basic parameters:&lt;/p>
&lt;pre>&lt;code>parameters(tidy_boosted_model)
## Collection of 3 parameters for tuning
##
## identifier type object
## trees trees nparam[+]
## min_n min_n nparam[+]
## learn_rate learn_rate nparam[+]
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>&lt;code>trees&lt;/code>: An integer for the number of trees contained in the ensemble.&lt;/li>
&lt;li>&lt;code>min_n&lt;/code>: An integer for the minimum number of data points in a node that is required for the node to be split further.&lt;/li>
&lt;li>&lt;code>learn_rate&lt;/code>: A number for the rate at which the boosting algorithm adapts from iteration-to-iteration (specific engines only).&lt;/li>
&lt;/ul>
&lt;p>Knn has a single parameter to tune: the neighbors&lt;/p>
&lt;pre>&lt;code>parameters(tidy_knn_model)
## Collection of 1 parameters for tuning
##
## identifier type object
## neighbors neighbors nparam[+]
&lt;/code>&lt;/pre>
&lt;ul>
&lt;li>&lt;code>neighbors&lt;/code>: A single integer for the number of neighbors to consider
(often called k). For kknn, a value of 5 is used if neighbors is not
specified.&lt;/li>
&lt;/ul>
&lt;p>So, we can use &lt;code>dials&lt;/code> to set the possible parameter values, which can
then be tuned using &lt;code>tune&lt;/code>.&lt;/p>
&lt;pre>&lt;code># Dials creates the parameter grids
# Tune applies the parameter grid to the models
# Dials pacakge
boosted_params &amp;lt;- 5
knn_params &amp;lt;- 10
?grid_regular
## starting httpd help server ... done
boosted_grid &amp;lt;- grid_regular(parameters(tidy_boosted_model), levels = boosted_params)
boosted_grid
## # A tibble: 125 x 3
## trees min_n learn_rate
## &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt;
## 1 1 2 0.0000000001
## 2 500 2 0.0000000001
## 3 1000 2 0.0000000001
## 4 1500 2 0.0000000001
## 5 2000 2 0.0000000001
## 6 1 11 0.0000000001
## 7 500 11 0.0000000001
## 8 1000 11 0.0000000001
## 9 1500 11 0.0000000001
## 10 2000 11 0.0000000001
## # ... with 115 more rows
knn_grid &amp;lt;- grid_regular(parameters(tidy_knn_model), levels = knn_params)
knn_grid
## # A tibble: 10 x 1
## neighbors
## &amp;lt;int&amp;gt;
## 1 1
## 2 2
## 3 4
## 4 5
## 5 7
## 6 8
## 7 10
## 8 11
## 9 13
## 10 15
&lt;/code>&lt;/pre>
&lt;p>Implement tuning grid using &lt;code>tune&lt;/code>:&lt;/p>
&lt;h1 id="tune">&lt;code>tune&lt;/code>&lt;/h1>
&lt;pre>&lt;code># install.packages(c(&amp;quot;xgboost&amp;quot;, &amp;quot;kknn&amp;quot;))
library(xgboost)
library(kknn)
# Tune pacakge
# system.time(
# boosted_tune &amp;lt;- tune_grid(tidy_boosted_model,
# tidy_rec,
# resamples = tidy_kfolds,
# grid = boosted_grid)
# )
# write_rds(boosted_tune, &amp;quot;boosted_tune.rds&amp;quot;)
boosted_tune &amp;lt;- read_rds(&amp;quot;boosted_tune.rds&amp;quot;)
# system.time(
# knn_tune &amp;lt;- tune_grid(tidy_knn_model,
# tidy_rec,
# resamples = tidy_kfolds,
# grid = knn_grid)
# )
# write_rds(knn_tune, &amp;quot;knn_tune.rds&amp;quot;)
knn_tune &amp;lt;- read_rds(&amp;quot;knn_tune.rds&amp;quot;)
#Use Tune package to extract best parameters using ROC_AUC handtill
boosted_param &amp;lt;- boosted_tune %&amp;gt;% select_best(&amp;quot;roc_auc&amp;quot;)
knn_param &amp;lt;- knn_tune %&amp;gt;% select_best(&amp;quot;roc_auc&amp;quot;)
#Apply parameters to the models
tidy_boosted_model_final &amp;lt;- finalize_model(tidy_boosted_model, boosted_param)
tidy_knn_model_final &amp;lt;- finalize_model(tidy_knn_model, knn_param)
&lt;/code>&lt;/pre>
&lt;p>Now, well try different options from &lt;code>dials&lt;/code> for parameter tuning, using
two additional methods for grid specification:&lt;/p>
&lt;ul>
&lt;li>random grid with &lt;code>dials::grid_random&lt;/code>&lt;/li>
&lt;li>maximum entropy grid with &lt;code>dials::grid_max_entropy&lt;/code>&lt;/li>
&lt;/ul>
&lt;h2 id="grid_random">&lt;code>grid_random&lt;/code>&lt;/h2>
&lt;pre>&lt;code>boosted_grid_rand &amp;lt;- grid_random(parameters(tidy_boosted_model), size = boosted_params)
boosted_grid_rand
## # A tibble: 5 x 3
## trees min_n learn_rate
## &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt;
## 1 190 21 2.32e- 5
## 2 1816 12 3.60e- 8
## 3 293 28 3.14e-10
## 4 314 8 2.52e- 7
## 5 1363 5 5.92e- 6
knn_grid_rand &amp;lt;- grid_random(parameters(tidy_knn_model), size = knn_params)
knn_grid_rand
## # A tibble: 7 x 1
## neighbors
## &amp;lt;int&amp;gt;
## 1 1
## 2 10
## 3 5
## 4 3
## 5 11
## 6 8
## 7 2
# system.time(
# boosted_tune_rand &amp;lt;- tune_grid(tidy_boosted_model,
# tidy_rec,
# resamples = tidy_kfolds,
# grid = boosted_grid_rand)
# )
# write_rds(boosted_tune_rand, &amp;quot;boosted_tune_rand.rds&amp;quot;)
boosted_tune_rand &amp;lt;- read_rds(&amp;quot;boosted_tune_rand.rds&amp;quot;)
# system.time(
# knn_tune_rand &amp;lt;- tune_grid(tidy_knn_model,
# tidy_rec,
# resamples = tidy_kfolds,
# grid = knn_grid_rand)
# )
# write_rds(knn_tune_rand, &amp;quot;knn_tune_rand.rds&amp;quot;)
knn_tune_rand &amp;lt;- read_rds(&amp;quot;knn_tune_rand.rds&amp;quot;)
#Use Tune package to extract best parameters using ROC_AUC handtill
boosted_param_rand &amp;lt;- boosted_tune_rand %&amp;gt;% select_best(&amp;quot;roc_auc&amp;quot;)
knn_param_rand &amp;lt;- knn_tune_rand %&amp;gt;% select_best(&amp;quot;roc_auc&amp;quot;)
&lt;/code>&lt;/pre>
&lt;h2 id="grid_max_entropy">&lt;code>grid_max_entropy&lt;/code>&lt;/h2>
&lt;pre>&lt;code>boosted_grid_maxent &amp;lt;- grid_max_entropy(parameters(tidy_boosted_model), size = boosted_params)
boosted_grid_maxent
## # A tibble: 5 x 3
## trees min_n learn_rate
## &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt;
## 1 433 25 4.27e-10
## 2 1671 13 3.28e-10
## 3 1520 3 3.21e- 6
## 4 672 3 3.06e-10
## 5 1371 22 2.32e- 5
knn_grid_maxent &amp;lt;- grid_max_entropy(parameters(tidy_knn_model), size = knn_params)
knn_grid_maxent
## # A tibble: 10 x 1
## neighbors
## &amp;lt;int&amp;gt;
## 1 3
## 2 10
## 3 1
## 4 15
## 5 13
## 6 4
## 7 6
## 8 8
## 9 9
## 10 11
# system.time(
# boosted_tune_maxent &amp;lt;- tune_grid(tidy_boosted_model,
# tidy_rec,
# resamples = tidy_kfolds,
# grid = boosted_grid_maxent)
# )
# write_rds(boosted_tune_maxent, &amp;quot;boosted_tune_maxent.rds&amp;quot;)
boosted_tune_maxent &amp;lt;- read_rds(&amp;quot;boosted_tune_maxent.rds&amp;quot;)
# system.time(
# knn_tune_maxent &amp;lt;- tune_grid(tidy_knn_model,
# tidy_rec,
# resamples = tidy_kfolds,
# grid = knn_grid_maxent)
# )
# write_rds(knn_tune_maxent, &amp;quot;knn_tune_maxent.rds&amp;quot;)
knn_tune_maxent &amp;lt;- read_rds(&amp;quot;knn_tune.rds&amp;quot;)
#Use Tune package to extract best parameters using ROC_AUC handtill
boosted_param_maxent &amp;lt;- boosted_tune_maxent %&amp;gt;% select_best(&amp;quot;roc_auc&amp;quot;)
knn_param_maxent &amp;lt;- knn_tune_maxent %&amp;gt;% select_best(&amp;quot;roc_auc&amp;quot;)
&lt;/code>&lt;/pre>
&lt;h1 id="workflows">&lt;code>workflows&lt;/code>&lt;/h1>
&lt;h3 id="for-combining-model-parameters-and-preprocessing">For combining model, parameters, and preprocessing&lt;/h3>
&lt;pre>&lt;code>boosted_wf &amp;lt;- workflow() %&amp;gt;%
add_model(tidy_boosted_model_final) %&amp;gt;%
add_recipe(tidy_rec)
knn_wf &amp;lt;- workflow() %&amp;gt;%
add_model(tidy_knn_model_final) %&amp;gt;%
add_recipe(tidy_rec)
&lt;/code>&lt;/pre>
&lt;h1 id="yardstick">&lt;code>yardstick&lt;/code>&lt;/h1>
&lt;h3 id="for-extracting-metrics-from-the-model">For extracting metrics from the model&lt;/h3>
&lt;pre>&lt;code>boosted_res &amp;lt;- last_fit(boosted_wf, tidy_split)
knn_res &amp;lt;- last_fit(knn_wf, tidy_split)
mods &amp;lt;- bind_rows(
boosted_res %&amp;gt;% mutate(model = &amp;quot;xgb&amp;quot;),
knn_res %&amp;gt;% mutate(model = &amp;quot;knn&amp;quot;)) %&amp;gt;%
unnest(.metrics)
ggplot(bind_rows(mods$.predictions), aes(Order, .pred_Anura)) +
geom_boxplot()
&lt;/code>&lt;/pre>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt=" " srcset="
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-17-1_hu4668447301989144043.webp 400w,
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-17-1_hu12140637065517628874.webp 760w,
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-17-1_hu14879292936314113267.webp 1200w"
src="https://alexbaecher.com/media/posts/script_files/figure-markdown_strict/unnamed-chunk-17-1_hu4668447301989144043.webp"
width="672"
height="480"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
&lt;/figcaption>&lt;/figure>
&lt;pre>&lt;code>ggplot(bind_rows(mods$.predictions), aes(Order, .pred_Caudata)) +
geom_boxplot()
&lt;/code>&lt;/pre>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt=" " srcset="
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-17-2_hu14706677157536861233.webp 400w,
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-17-2_hu17734957877442164994.webp 760w,
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-17-2_hu3054777465481101903.webp 1200w"
src="https://alexbaecher.com/media/posts/script_files/figure-markdown_strict/unnamed-chunk-17-2_hu14706677157536861233.webp"
width="672"
height="480"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
&lt;/figcaption>&lt;/figure>
&lt;pre>&lt;code>ggplot(mods, aes(x = model, y = .estimate, col = model)) +
geom_point() +
facet_wrap(~.metric)
&lt;/code>&lt;/pre>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt=" " srcset="
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-17-3_hu7929835404271128727.webp 400w,
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-17-3_hu5960965889861658502.webp 760w,
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-17-3_hu8034350242501598142.webp 1200w"
src="https://alexbaecher.com/media/posts/script_files/figure-markdown_strict/unnamed-chunk-17-3_hu7929835404271128727.webp"
width="672"
height="480"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
&lt;/figcaption>&lt;/figure>
&lt;p>Confusion matrix to visualize model predictions against truth&lt;/p>
&lt;pre>&lt;code>boosted_res %&amp;gt;% unnest(.predictions) %&amp;gt;%
conf_mat(truth = Order, estimate = .pred_class) %&amp;gt;%
autoplot()
&lt;/code>&lt;/pre>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt=" " srcset="
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-18-1_hu925915619049730072.webp 400w,
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-18-1_hu1067537527602828794.webp 760w,
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-18-1_hu17114581279966710681.webp 1200w"
src="https://alexbaecher.com/media/posts/script_files/figure-markdown_strict/unnamed-chunk-18-1_hu925915619049730072.webp"
width="672"
height="480"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
&lt;/figcaption>&lt;/figure>
&lt;h3 id="fit-the-entire-data-set-using-the-final-wf">Fit the entire data set using the final wf&lt;/h3>
&lt;pre>&lt;code>final_boosted_model &amp;lt;- fit(boosted_wf, amphibio)
## [15:25:37] WARNING: amalgamation/../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
final_knn_model &amp;lt;- fit(knn_wf, amphibio)
&lt;/code>&lt;/pre>
&lt;h1 id="broom">&lt;code>broom&lt;/code>&lt;/h1>
&lt;p>Now we can use &lt;code>broom&lt;/code> to tidy the results from these models, and
provide an intuitive view of their meaning!&lt;/p>
&lt;h2 id="augment">&lt;code>augment()&lt;/code>&lt;/h2>
&lt;p>First, we’ll use &lt;code>augment&lt;/code> to obtain predictions, residuals, and other
items from the model, which auto-binds them to the original dataset.&lt;/p>
&lt;pre>&lt;code>boosted_aug &amp;lt;- augment(final_boosted_model, new_data = amphibio[,-1])
knn_aug &amp;lt;- augment(final_knn_model, new_data = amphibio[,-1])
boosted_aug_long &amp;lt;- boosted_aug %&amp;gt;%
pivot_longer(-c(.pred_class, .pred_Anura, .pred_Caudata), names_to = &amp;quot;predictor&amp;quot;, values_to = &amp;quot;value&amp;quot;)
&lt;/code>&lt;/pre>
&lt;h2 id="now-we-can-evaluate-the-models-using-yardstick">Now we can evaluate the models using &lt;code>yardstick&lt;/code>!&lt;/h2>
&lt;h1 id="yardstick-1">&lt;code>yardstick&lt;/code>&lt;/h1>
&lt;pre>&lt;code>final_boosted_model %&amp;gt;%
predict(bake(tidy_rec, new_data = tidy_test), type = &amp;quot;prob&amp;quot;) %&amp;gt;%
bind_cols(tidy_test) %&amp;gt;%
roc_auc(factor(Order), .pred_Anura)
## # A tibble: 1 x 3
## .metric .estimator .estimate
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
## 1 roc_auc binary 0.759
final_boosted_model %&amp;gt;%
predict(bake(tidy_rec, new_data = tidy_test), type = &amp;quot;prob&amp;quot;) %&amp;gt;%
bind_cols(tidy_test) %&amp;gt;%
roc_curve(factor(Order), .pred_Anura) %&amp;gt;%
autoplot()
&lt;/code>&lt;/pre>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt=" " srcset="
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-21-1_hu6876896358977779037.webp 400w,
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-21-1_hu15580196728854118655.webp 760w,
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-21-1_hu3457540179927346600.webp 1200w"
src="https://alexbaecher.com/media/posts/script_files/figure-markdown_strict/unnamed-chunk-21-1_hu6876896358977779037.webp"
width="672"
height="480"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
&lt;/figcaption>&lt;/figure>
&lt;h2 id="evaluating-knn-model">Evaluating knn model&lt;/h2>
&lt;pre>&lt;code>final_knn_model %&amp;gt;%
predict(bake(tidy_rec, new_data = tidy_test), type = &amp;quot;prob&amp;quot;) %&amp;gt;%
bind_cols(tidy_test) %&amp;gt;%
roc_auc(factor(Order), .pred_Anura)
## # A tibble: 1 x 3
## .metric .estimator .estimate
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
## 1 roc_auc binary 0.5
final_knn_model %&amp;gt;%
predict(bake(tidy_rec, new_data = tidy_test), type = &amp;quot;prob&amp;quot;) %&amp;gt;%
bind_cols(tidy_test) %&amp;gt;%
roc_curve(factor(Order), .pred_Anura) %&amp;gt;%
autoplot()
&lt;/code>&lt;/pre>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt=" " srcset="
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-22-1_hu15917107705313701047.webp 400w,
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-22-1_hu18171846850144008820.webp 760w,
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-22-1_hu11196280528281156913.webp 1200w"
src="https://alexbaecher.com/media/posts/script_files/figure-markdown_strict/unnamed-chunk-22-1_hu15917107705313701047.webp"
width="672"
height="480"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
&lt;/figcaption>&lt;/figure>
&lt;pre>&lt;code>final_knn_model %&amp;gt;%
predict(bake(tidy_rec, new_data = tidy_test), type = &amp;quot;prob&amp;quot;) %&amp;gt;%
bind_cols(tidy_test) %&amp;gt;%
roc_auc(factor(Order), .pred_Anura)
## # A tibble: 1 x 3
## .metric .estimator .estimate
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
## 1 roc_auc binary 0.5
&lt;/code>&lt;/pre>
&lt;h2 id="visualizing-predictions">Visualizing predictions:&lt;/h2>
&lt;pre>&lt;code>library(viridis)
## Loading required package: viridisLite
##
## Attaching package: 'viridis'
## The following object is masked from 'package:scales':
##
## viridis_pal
ggplot(boosted_aug_long, aes(x = value, y = .pred_Anura, col = .pred_class)) +
geom_point() +
facet_wrap(~predictor) +
scale_color_viridis_d(&amp;quot;Truth&amp;quot;, option = &amp;quot;D&amp;quot;) +
theme_bw()
&lt;/code>&lt;/pre>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt=" " srcset="
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-23-1_hu9070272248444432199.webp 400w,
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-23-1_hu16889084873753849499.webp 760w,
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-23-1_hu4124343322066363760.webp 1200w"
src="https://alexbaecher.com/media/posts/script_files/figure-markdown_strict/unnamed-chunk-23-1_hu9070272248444432199.webp"
width="672"
height="480"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
&lt;/figcaption>&lt;/figure>
&lt;pre>&lt;code>ggplot(boosted_aug_long, aes(x = value, y = .pred_Caudata, col = .pred_class)) +
geom_point() +
facet_wrap(~predictor) +
scale_color_viridis_d(&amp;quot;Truth&amp;quot;, option = &amp;quot;D&amp;quot;) +
theme_bw()
&lt;/code>&lt;/pre>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt=" " srcset="
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-23-2_hu17258803858476358636.webp 400w,
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-23-2_hu6041234132259651925.webp 760w,
/media/posts/script_files/figure-markdown_strict/unnamed-chunk-23-2_hu6316135883687380815.webp 1200w"
src="https://alexbaecher.com/media/posts/script_files/figure-markdown_strict/unnamed-chunk-23-2_hu17258803858476358636.webp"
width="672"
height="480"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
&lt;/figcaption>&lt;/figure></description></item></channel></rss>